{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using load_iris for iris and genfromtxt for ionosphere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()                #Loading Iris Dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "ionos = np.genfromtxt(\"ionosphere.txt\",delimiter=\",\") #loading Ionosphere using genfromtext for converting into values\n",
    "type(ionos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Splitting the dataset into the training and test sets. using the function\n",
    "train_test_split in scikit-learn, in which case use your birthday in\n",
    "the format DDMM as random_state (omit leading zeros if any)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 1 1 1 1 0 2 2 1 1 2 0 2 2 2 2 0 1 1 0 2 0 1 2 2 0 0 1 1 0 2 0 0 2 2 2\n",
      " 2 0 1 2 0 2 1 2 0 1 0 1 0 1 1 2 2 1 0 1 2 1 2 0 0 2 0 2 2 0 1 2 1 2 0 0 0\n",
      " 2 0 0 1 0 2 1 0 2 0 1 1 1 1 0 1 1 0 2 1 0 1 1 0 1 2 2 2 1 2 0 1 2 1 2 2 1\n",
      " 2 1 0 0 2 0 0 1 2]\n",
      "[0 0 1 1 1 2 0 0 1 1 1 0 0 2 0 1 1 2 0 0 0 2 2 0 1 2 0 2 0 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(iris['data'],iris['target'], test_size=0.2, random_state=2805) \n",
    "                                                      #random state=DDMM(Birthdate) is for getting same output in multiple runs\n",
    "print(y_train)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(351, 34)\n",
      "(351,)\n",
      "[[ 1.       0.       1.      ... -0.89093  0.22995 -0.89158]\n",
      " [ 1.       0.       0.8471  ... -0.06678  0.85764 -0.06151]\n",
      " [ 1.       0.       0.76296 ... -0.27105  1.      -0.57037]\n",
      " ...\n",
      " [ 0.       0.       1.      ...  1.       0.       0.     ]\n",
      " [ 1.       0.       0.8811  ...  0.05488  0.97561 -0.0122 ]\n",
      " [ 1.       0.       0.95882 ... -0.10797  0.93144 -0.06888]]\n",
      "[[ 0.       0.       0.      ...  1.       0.       0.     ]\n",
      " [ 1.       0.       0.95659 ... -0.39061  0.82166 -0.41173]\n",
      " [ 1.       0.       1.      ...  1.       1.       1.     ]\n",
      " ...\n",
      " [ 1.       0.       0.      ...  0.       0.       0.     ]\n",
      " [ 1.       0.       0.4987  ... -0.05455  0.58961 -0.08571]\n",
      " [ 0.       0.       1.      ...  0.       1.      -1.     ]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "ion = pd.DataFrame(ionos) #DataFrame is used as a Two-Dimensional tabular data structure with labelled axes(rows,columns) \n",
    "                            #so that iloc function can access the index values from dataset.\n",
    "ion.head()\n",
    "x1 = ion.iloc[:,:-1].values\n",
    "y1=ion.iloc[:,-1].values\n",
    "print(x1.shape)\n",
    "print(y1.shape)\n",
    "x1_train,x1_test,y1_train,y1_test = train_test_split(x1,y1, test_size=0.2, random_state=2805) \n",
    "print(x1_train)\n",
    "print(x1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the Nearest Neighbour method (i.e., the 1 Nearest Neighbours\n",
    "method). Run it on both datasets: train it on the training set and compute\n",
    "the number of errors it makes on the test set and the test error rate (the\n",
    "ratio of the number of errors to the size of the test set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "def Euclidean_Dist(x_train, x_test): \n",
    "    sum = 0\n",
    "    for i in range(len(x_train)):        #Accepting all the elements in x_train using len function\n",
    "        diff = x_test[i] - x_train[i]    #for calculating distance between test samples and train samples  \n",
    "        sum = sum + (diff * diff)\n",
    "        d = np.sqrt(sum)    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris Data Accuracy for K=3:  0.9333333333333333\n",
      "Error Rate for 0.06666666666666665\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3)# to implement for 3 nearest neighbor\n",
    "\n",
    "def predict(x_train,x_test,y_train): #general function for implementation of nearest neighbor\n",
    "    labels = []    #for storing prediction labels\n",
    "    distances = [] #for storing distances\n",
    "    for i in range(len(x_test)):                         \n",
    "        for j in range(len(x_train)):\n",
    "            cal_dist = Euclidean_Dist(x_train[j],x_test[i])\n",
    "            distances.append(cal_dist)                       #storing the element of  calculated distances using append \n",
    "        minIndex=distances.index(min(distances))\n",
    "        a=y_train[minIndex]                         \n",
    "        labels.append(a)          #for aSppending predicted labels into array\n",
    "        distances.clear()         #For flushing the array\n",
    "        \n",
    "    return labels\n",
    "knn.fit(x_train,y_train)\n",
    "y = knn.score(x_test,y_test) #knn for Iris Data Set\n",
    "print(\"Iris Data Accuracy for K=3: \",y)\n",
    "k_error_rate = print(\"Error Rate for\", 1 - y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ionosphere data Accuracy for K=3:  0.8450704225352113\n",
      "Error Rate for 0.15492957746478875\n"
     ]
    }
   ],
   "source": [
    "knn.fit(x1_train,y1_train)\n",
    "knn.predict(x1_test)\n",
    "a = knn.score(x1_test,y1_test) #knn for Ionosphere Data Set\n",
    "print(\"Ionosphere data Accuracy for K=3: \",a)\n",
    "k_error_rate = print(\"Error Rate for\", 1 - a) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for IRIS : 0.9333333333333333\n",
      "No. of errors:  2\n",
      "Error Rate: 0.06666666666666665\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict(x_train,x_test,y_train) \n",
    "Accuracy_IRIS = np.mean(y_pred==y_test)  #Accuracy for Iris data for nn\n",
    "\n",
    "no = 0\n",
    "size =  y_test.shape[0]\n",
    "for x in range(size):\n",
    "    if(y_pred[x] != y_test[x]):      #to get error which are not similar\n",
    "        no=no+1\n",
    "print(\"Accuracy for IRIS :\", Accuracy_IRIS)\n",
    "print(\"No. of errors: \",no)                    \n",
    "Error_rate_IRIS = 1 -  np.mean(y_pred==y_test)     #Error rate for Iris data\n",
    "print(\"Error Rate:\",Error_rate_IRIS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Ionosphere : 0.8450704225352113\n",
      "No. of errors:  11\n",
      "Error Rate:  0.15492957746478875\n"
     ]
    }
   ],
   "source": [
    "y1_pred = predict(x1_train,x1_test,y1_train)\n",
    "Accuracy_Ionos = np.mean(y1_pred == y1_test) #Accuracy for Ionosphere\n",
    "no = 0\n",
    "size =  y1_test.shape[0]\n",
    "for x in range(size):\n",
    "    if(y1_pred[x] != y1_test[x]):\n",
    "        no=no+1\n",
    "print(\"Accuracy for Ionosphere :\", Accuracy_Ionos)\n",
    "print(\"No. of errors: \",no)\n",
    "Error_rate_IONOS = 1 - np.mean(y1_pred==y1_test)#Error Rate for Ionosphere Data\n",
    "print(\"Error Rate: \",Error_rate_IONOS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
